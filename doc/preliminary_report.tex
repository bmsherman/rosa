\documentclass[10pt]{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry} % see geometry.pdf on how to lay out the page. There's lots.
\geometry{a4paper}

\input{common}

\newcommand{\lv}{\lVert}
\newcommand{\rv}{\rVert}
\newcommand{\tl}{\tilde}
\newcommand{\eqn}[1]{
 \begin{align} #1
 \end{align}}


\setlength{\parindent}{0pt}



\title{On (More) Precise Propagation of (Roundoff) Errors}
\author{}

\begin{document}

\maketitle



\section{}
Consider the case of a generic loop, iteratively applying a function $f$.
\begin{figure}[h!]
  \centering
  \lstset{numbers=none}
  \begin{subfigure}[b]{0.25\textwidth}
    \begin{lstlisting}
var x1 = ???
var x2 = ???
while(i < N) {
  (x1, x2) = f(x1, x2)
}
(x1, x2)
    \end{lstlisting}
    %\caption{A gull}
    %\label{fig:gull}
  \end{subfigure}%
  ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
    %(or a blank line to force the subfigure onto a new line)
  \begin{subfigure}[b]{0.32\textwidth}
    \begin{lstlisting}
    val x1, x2 = ???

    def iter(x1, x2, i) = {
      if (i < N) {
        val (y1, y2) = f(x1, x2)
        iter(y1, y2, i + 1)
      } else {
        (x1, x2)
      }
    }
    \end{lstlisting}
    %\caption{A tiger}
    %\label{fig:tiger}
  \end{subfigure}
  ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
    %(or a blank line to force the subfigure onto a new line)
  \begin{subfigure}[b]{0.32\textwidth}
    \begin{lstlisting}
    val x1, x2 = ???

    def iter(x1, x2, i) = {
      if (i < N) {
        val (y1, y2) = iter(x1, x2, i + 1)
        f(y1, y2)
      } else {
        (x1, x2)
      }
    }
    \end{lstlisting}
    %\caption{A mouse}
    %\label{fig:mouse}
  \end{subfigure}
  %\caption{Pictures of animals}\label{fig:animals}
\end{figure}


We want to find an inductive specification about the output range and output errors.



\paragraph{Notation:} Let
\begin{itemize}
\item $f$ denote the mathematical function $f: \mathbb{R}^n \to \mathbb{R}^n$
\item $\tilde{f}$ be the finite-precision version of $f$
\item $\tilde{x}$ be the finite-precision, actually computed, value corresponding to the
ideal variable $x$
\item $\lambda$ be an upper bound on the initial error, i.e. $\lv x - \tilde{x} \rv$
\item $\sigma$ be the roundoff error on evaluating $f$ with exact inputs, i.e.
  $\lv f(x) - \tilde{f}(x) \rv$
\end{itemize}
where $f$ and $x$ may be vectors, in which case the definitions are component-wise.

\subsection{Division of error}
The overall error on evaluating $f$ in finite-precision arithmetic is
  $\lv f(x) - \tilde{f}(\tilde{x}) \rv$, where $\lv x - \tilde{x} \rv \le \lambda$.

\begin{align}
\lv f(x) - \tilde{f}(\tilde{x}) \rv &=
 \lv f(x) - f(\tilde{x}) + f(\tilde{x}) - \tilde{f}(\tilde{x}) \rv \\
 &\le \lv f(x) - f(\tilde{x}) \rv + \lv f(\tilde{x}) - \tilde{f}(\tilde{x}) \rv
\end{align}

Suppose there is a function $g$, such that $\lv f(x) - f(y) \rv \le g(\lv x - y \rv)$.
Further note that $\lv f(\tilde{x}) - \tilde{f}(\tilde{x}) \rv$ is the roundoff error on
computing $f$ with exact inputs. Then,

\begin{align}
\label{errorLoopBody}
\lv f(x) - \tilde{f}(\tilde{x}) \rv &\le g(\lv x - y \rv) + \sigma
\end{align}
We have thus separated the overall error into the error from propagating
the initial uncertainty and the roundoff error.

Consider iterating $f$, i.e. we are computing $f^n(x) = f(f(...f(x)))$.

{\bf Claim: }
\begin{equation}
\lv f^n(x) - \tl{f}^n(\tl{x})\rv \le \sigma + \sum^{n - 1}_{i = 1} g^i(\sigma) + g^n(\lv x - \tl{x} \rv)
\end{equation}

We show this by induction. The base case, for $n = 1$ is shown above.
\begin{align}
\lv  f^n(x) - \tl{f}^n(\tl{x})\rv &\le
  \lv f^n(x) - f(\tl{f}^{n-1}(\tl{x})) \rv + \lv f(\tl{f}^{n-1}(\tl{x})) - \tl{f}^n(\tl{x})\rv \\
  &\le g(\lv f^{n-1}(x) - \tl{f}^{n-1}(\tl{x}) \rv) + \sigma \\
  &\le g (\sigma + \sum^{n - 2}_{i = 1} g^i(\sigma) + g^{n-1}(\lv x - \tl{x} \rv)) + \sigma \\
  &\le \sigma + \sum^{n - 1}_{i = 1} g^i(\sigma) + g^n(\lv x - \tl{x} \rv)
\end{align}

\subsection{Lipschitz continuity}
Now consider $g(x) = K \cdot x$, i.e. which yields Lipschitz continuity:
$\lv f(x) - f(y) \rv \le K \lv x - y \rv$.
Note that we need to compute the Lipschitz constant for the mathematical function $f$,
and not for $\tl{f}$.
The expression for the error then becomes
\begin{align}
\lv f^n(x) - \tl{f}^n(\tl{x})\rv \le K^n + \sum^{n-1}_{i=0}K^i \sigma
  = K^n \lambda + \sigma \sum^{n-1}_{i=0} K^i
  = K^n \lambda + \sigma \left(\dfrac{1 - K^n}{1-K} \right)
\end{align}
when $K \ne 1$.
When $K = 1$, $g$ becomes the identity function and so
\begin{align}
\lv f^n(x) - \tl{f}^n(\tl{x})\rv \le \sigma + \sum^{n-1}_{i=1}\sigma + \lambda
= n \cdot \sigma + \lambda
\end{align}

We want to compute the Lipschitz constant for a function $f: \mathbb{R}^n \to \mathbb{R}$,
that is, we are computing one constant for each output of the function.

Let $h: [0, 1] \to \mathbb{R}$ such that $h(\theta) := f(z + \theta(y-z))$.
Then $h(0) = f(z)$ and $h(1) = f(y)$ and
\eqn{
  \frac{d}{d\theta}f(\theta) &= \nabla f(z + \theta(y-z)) \cdot (y-z)
}

\eqn{
  f(y) - f(z) &= f(1) -f(0) = \int^1_0 f'(\theta)d\theta
  = \int^1_0\nabla f(z + \theta(y-z)) d\theta \cdot (y-z)
}

\eqn{
  \lv f(y) - f(z) \rv &= \lv \int^1_0\nabla f(z + \theta(y-z)) d\theta \cdot (y-z) \rv \\
&le \int^1_0 \lv \nabla f(z + \theta(y-z))  \cdot (y-z) \rv d\theta \quad
   \text{ (triangle inequality for integrals)}\\
&\le \sup\limits_{\theta\in [0,1]} \lv \nabla f(z + \theta(y-z))  \cdot (y-z) \rv \int^1_0 d\theta\\
\label{eqnG}
&= \sup\limits_{\theta\in [0,1]} \lv \nabla f(z + \theta(y-z))  \cdot (y-z) \rv \\
&\le \sup\limits_{\theta\in [0,1]} \lv \nabla f(z + \theta(y-z))  \rv \rv (y-z) \rv
}

Since $f(y) - f(z) \in \mathbb{R}$, all vectors norms $\lv f(y) - f(z) \rv$
are equivalent to $|f(y) - f(z)|$ and we can choose any norm.

If possible (and correct!), for precision reasons, we may want to already use Equation \ref{eqnG}  i.e.
\eqn{
  g(x) = \sup\limits_{\theta\in [0,1]} \lv \nabla f(z + \theta(y-z))(x)\rv
}

Thus, in order to compute the Lipschitz constant, we need to bound the gradient of $f$
over the specified input range.


%\subsection{Applications}
%\begin{itemize}
%\item more precise error computation
%\item loops
%\item modular composition of functions
%\item input sensitivity information
%\end{itemize}


\section{Preliminary manual experiments}

\subsection{Harmonic oscillator}
\eqn{
  f_1(x, v) &= x + v \cdot dt\\
  f_2(x, v) &= v - k \cdot x \cdot dt
}

Assume input ranges $x \in [0.15, 0.25]$ and $v \in [3.35, 3.45]$
and parameter $k = 2.3, dt = 0.1$.
Then $K = 1$ and our method can recover that errors are merely being added in this case.


\begin{figure}[h!]
  \centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{images/harmonic_euler}
%\caption{A gull}
%\label{fig:gull}
\end{subfigure}%
~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
  %(or a blank line to force the subfigure onto a new line)
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{images/harmonic_rk2}
%\caption{A tiger}
%\label{fig:tiger}
\end{subfigure}
\caption{True errors for harmonic oscillator}
\label{fig:harmonic}
\end{figure}




\subsection{2-body simulation}
\begin{figure}[h!]
  \centering
\includegraphics[width=\textwidth]{images/nbody}
  \caption{True errors for nbody simulation}
\label{fig:2body}
\end{figure}

\subsection{Predator-Prey}
Simulation of a hare and lynx population.
\eqn{
  \frac{dH}{dt} &= r H (1 - \frac{H}{k}) - \frac{a H L}{c + H}\\
  \frac{dL}{dt} &= \frac{b a H L}{c + H} - d L
}
$a = 3.2, b = 0.6, c = 50, d = 0.56, k = 125.0, r = 1.6$
$H \in [0, 90], L \in [0, 90]$

Solving this with Euler's method:
\eqn{
  f_1 = H + dt * \frac{dH}{dt} \qquad f_2 = L + dt * \frac{dL}{dt}
}

We have (so far) computed
\eqn{
  \sup \frac{\partial f_1}{\partial H} \le 1.6
}
This is bad news, since it means that after only 10 iterations, roundoff errors
get magnified by a factor of 182 (as computed with $\frac{1-K^n}{1-K}$).

A quick experiment showed, however, that if can constraint the variables further,
for example by using some (hopefully present) relationship between $H$ and $L$,
then we can also shrink the Lipschitz constant $K$.


\begin{figure}[h!]
  \centering
\includegraphics[width=\textwidth]{images/predator-prey}
  \caption{True errors for predator-prey simulation}
\label{fig:predator}
\end{figure}

\subsection{Jet engine and doppler revisited}
We can use Equation~\ref{errorLoopBody} to compute the overall error for
a loop-free function.
The jet-engine example is function of two variables $f(x_1, x_2)$.
Using our range computation we can bound the components of the gradient
over the input ranges $x_1 \in [-5, 5], x_2 \in [-20, 5]$
\eqn{
  \frac{d f}{d x_1} \in [-3555, 3440] \qquad \frac{d f}{d x_2} \in [-152, 270]
}
The roundoff error for exact inputs is $1.61703982148642E-08$, as computed by Rosa.
Then, including the initial errors on $x_1, x_2 = 1e-8$, we have by
Equation~\ref{errorLoopBody}:
\eqn{
\text{total error} \le \sigma + K * \lambda \le 1.62e-08 + 3555 * 1e-8 = 3.557e-8
}
The total error computed for this example computed by Rosa with our old technique
is $0.140017339985495$, four orders of magnitude larger.

Similarly, for the computation of the doppler shift (a much smaller, but nonlinear example),
we can approximately half the error from $2.35478453236889e-06$ to $1.13e-6$.

\subsection{Further experiments:}
Mean, standard deviation and variance, damped oscillator.
To follow.

%\subsection{Newton's method}

% \section{Possible extensions}
% \subsection{Adding other errors within the same model}
% e.g. truncation errors, as long as they only depend on the range in some way

% \section{Other aspects}

% specification language allowing different inductive formulations
\end{document}
